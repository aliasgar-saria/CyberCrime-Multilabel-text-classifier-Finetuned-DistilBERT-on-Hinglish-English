{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        self.categories = [\n",
    "            \"Any Other Cyber Crime\",\n",
    "            \"Crime Against Women & Children\",\n",
    "            \"Cryptocurrency Crime\",\n",
    "            \"Cyber Attack/ Dependent Crimes\",\n",
    "            \"Cyber Terrorism\",\n",
    "            \"Hacking Damage to computercomputer system etc\",\n",
    "            \"Online Cyber Trafficking\",\n",
    "            \"Online Financial Fraud\",\n",
    "            \"Online Gambling Betting\",\n",
    "            \"Online and Social Media Related Crime\",\n",
    "            \"Ransomware\",\n",
    "            \"Report Unlawful Content\"\n",
    "        ]\n",
    "        self.subcategories_map = {\n",
    "            \"Any Other Cyber Crime\": [\"Other\"],\n",
    "            \"Crime Against Women & Children\": [\n",
    "                \"Computer Generated CSAM/CSEM\",\n",
    "                \"Cyber Blackmailing & Threatening\",\n",
    "                \"Sexual Harassment\"\n",
    "            ],\n",
    "            \"Cryptocurrency Crime\": [\"Cryptocurrency Fraud\"],\n",
    "            \"Cyber Attack/ Dependent Crimes\": [\n",
    "                \"Data Breach/Theft\",\n",
    "                \"Denial of Service (DoS)/Distributed Denial of Service (DDOS) attacks\",\n",
    "                \"Hacking/Defacement\",\n",
    "                \"Malware Attack\",\n",
    "                \"Ransomware Attack\", \n",
    "                \"SQL Injection\",\n",
    "                \"Tampering with computer source documents\"\n",
    "            ],\n",
    "            \"Cyber Terrorism\": [\"Cyber Terrorism\"],\n",
    "            \"Hacking Damage to computercomputer system etc\": [\n",
    "                \"Damage to computer computer systems etc\",\n",
    "                \"Email Hacking\",\n",
    "                \"Tampering with computer source documents\",\n",
    "                \"Unauthorised AccessData Breach\",\n",
    "                \"Website DefacementHacking\"\n",
    "            ],\n",
    "            \"Online Cyber Trafficking\": [\"Online Trafficking\"],\n",
    "            \"Online Financial Fraud\": [\n",
    "                \"Business Email CompromiseEmail Takeover\",\n",
    "                \"DebitCredit Card FraudSim Swap Fraud\",\n",
    "                \"DematDepository Fraud\",\n",
    "                \"EWallet Related Fraud\",\n",
    "                \"Fraud CallVishing\",\n",
    "                \"Internet Banking Related Fraud\",\n",
    "                \"UPI Related Frauds\"\n",
    "            ],\n",
    "            \"Online Gambling Betting\": [\"Online Gambling Betting\"],\n",
    "            \"Online and Social Media Related Crime\": [\n",
    "                \"Cheating by Impersonation\",\n",
    "                \"Cyber Bullying Stalking Sexting\",\n",
    "                \"EMail Phishing\",\n",
    "                \"FakeImpersonating Profile\",\n",
    "                \"Impersonating Email\",\n",
    "                \"Intimidating Email\",\n",
    "                \"Online Job Fraud\",\n",
    "                \"Online Matrimonial Fraud\",\n",
    "                \"Profile Hacking Identity Theft\",\n",
    "                \"Provocative Speech for unlawful acts\"\n",
    "            ],\n",
    "            \"Ransomware\": [\"Ransomware\"],\n",
    "            \"Report Unlawful Content\": [\"Against Interest of sovereignty or integrity of India\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available categories: ['Online Financial Fraud' 'Crime Against Women & Children'\n",
      " 'Hacking  Damage to computercomputer system etc'\n",
      " 'Online and Social Media Related Crime' 'Any Other Cyber Crime'\n",
      " 'Cyber Attack/ Dependent Crimes' 'Cryptocurrency Crime'\n",
      " 'Online Cyber Trafficking' 'Cyber Terrorism' 'Online Gambling  Betting'\n",
      " 'Ransomware' 'Report Unlawful Content']\n",
      "Balanced dataset saved to 'balancedtrain.csv' with 8525 samples\n",
      "Category distribution in balanced dataset:\n",
      "category\n",
      "Online Financial Fraud                            1072\n",
      "Crime Against Women & Children                    1072\n",
      "Hacking  Damage to computercomputer system etc    1072\n",
      "Online and Social Media Related Crime             1072\n",
      "Any Other Cyber Crime                             1072\n",
      "Cyber Attack/ Dependent Crimes                    1072\n",
      "Online Cyber Trafficking                           540\n",
      "Cyber Terrorism                                    480\n",
      "Cryptocurrency Crime                               466\n",
      "Online Gambling  Betting                           436\n",
      "Ransomware                                         168\n",
      "Report Unlawful Content                              3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CybercrimeDataset(Dataset):\n",
    "    def __init__(self, texts, category_labels, subcategory_labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.category_labels = category_labels\n",
    "        self.subcategory_labels = subcategory_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        text = ' '.join(text.split())  # Clean extra spaces\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'category_labels': torch.FloatTensor(self.category_labels[idx]),\n",
    "            'subcategory_labels': torch.FloatTensor(self.subcategory_labels[idx])\n",
    "        }\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Basic text cleaning\n",
    "    text = str(text).lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def balance_dataset(df):\n",
    "    majority_classes = [\n",
    "        'Online Financial Fraud', 'Any Other Cyber Crime', 'Crime Against Women & Children','Cyber Attack/ Dependent Crimes',\n",
    "        'Online and Social Media Related Crime','Hacking  Damage to computercomputer system etc','Cyber Stalking','Cryptocurrency Crime'\n",
    "    ]\n",
    "    \n",
    "    severely_undersampled = [\n",
    "        \n",
    "        'Cyber Terrorism', \n",
    "        'Online Cyber Trafficking',\n",
    "        'Ransomware',\n",
    "        'Report Unlawful Content'\n",
    "    ]\n",
    "\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    print(\"Available categories:\", df['category'].unique())\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        try:\n",
    "            category_df = df[df['category'] == category]\n",
    "            subcategory_counts = category_df['sub_category'].value_counts()\n",
    "            \n",
    "            if len(category_df) < 2:\n",
    "                # Handle single sample cases by duplication\n",
    "                balanced_df = pd.concat([category_df] * 3)\n",
    "                \n",
    "            elif category in severely_undersampled:\n",
    "                # Triple the samples for severely undersampled categories\n",
    "                balanced_df = pd.concat([category_df] * 3)\n",
    "                \n",
    "            elif category in majority_classes:\n",
    "                # Reduce majority classes to median size\n",
    "                target_size = int(df['category'].value_counts().median())\n",
    "                balanced_df = category_df.sample(n=min(len(category_df), target_size), \n",
    "                                              random_state=42)\n",
    "            else:\n",
    "                # Keep other categories as is\n",
    "                balanced_df = category_df\n",
    "                \n",
    "            balanced_dfs.append(balanced_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Category '{category}' skipped due to: {str(e)}\")\n",
    "            balanced_dfs.append(category_df)\n",
    "    \n",
    "    return pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "def create_dataloaders(df, tokenizer, batch_size=16):\n",
    "    # Clean text\n",
    "    df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(lambda x: str(x).lower().strip())\n",
    "    \n",
    "    # Balance dataset\n",
    "    balanced_df = balance_dataset(df)\n",
    "    \n",
    "    # Save balanced dataset to CSV\n",
    "    balanced_df.to_csv('balancedtrain.csv', index=False)\n",
    "    print(f\"Balanced dataset saved to 'balancedtrain.csv' with {len(balanced_df)} samples\")\n",
    "    print(\"Category distribution in balanced dataset:\")\n",
    "    print(balanced_df['category'].value_counts())\n",
    "    \n",
    "    # Prepare labels\n",
    "    mlb_category = MultiLabelBinarizer()\n",
    "    mlb_subcategory = MultiLabelBinarizer()\n",
    "    \n",
    "    # Transform labels\n",
    "    category_encoded = mlb_category.fit_transform(\n",
    "        balanced_df['category'].apply(lambda x: [x])\n",
    "    )\n",
    "    subcategory_encoded = mlb_subcategory.fit_transform(\n",
    "        balanced_df['sub_category'].apply(lambda x: [x])\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = CybercrimeDataset(\n",
    "        balanced_df['crimeaditionalinfo'].values,\n",
    "        category_encoded,\n",
    "        subcategory_encoded,\n",
    "        tokenizer,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Create dataloader with balanced sampling\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader, mlb_category, mlb_subcategory\n",
    "\n",
    "# Usage example:\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('output_no_duplicates.csv')\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader, mlb_category, mlb_subcategory = create_dataloaders(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available categories: ['Online Financial Fraud' 'Crime Against Women & Children'\n",
      " 'Hacking  Damage to computercomputer system etc'\n",
      " 'Online and Social Media Related Crime' 'Any Other Cyber Crime'\n",
      " 'Cyber Attack/ Dependent Crimes' 'Cryptocurrency Crime'\n",
      " 'Online Cyber Trafficking' 'Cyber Terrorism' 'Online Gambling  Betting'\n",
      " 'Ransomware' 'Report Unlawful Content']\n",
      "\n",
      "Final category distribution:\n",
      "category\n",
      "Online Financial Fraud                            1072\n",
      "Crime Against Women & Children                    1072\n",
      "Hacking  Damage to computercomputer system etc    1072\n",
      "Online and Social Media Related Crime             1072\n",
      "Any Other Cyber Crime                             1072\n",
      "Cyber Attack/ Dependent Crimes                    1072\n",
      "Online Cyber Trafficking                           540\n",
      "Cyber Terrorism                                    480\n",
      "Cryptocurrency Crime                               466\n",
      "Ransomware                                         448\n",
      "Online Gambling  Betting                           436\n",
      "Report Unlawful Content                            350\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset saved to 'balancedtrain.csv' with 9152 samples\n",
      "Category distribution in balanced dataset:\n",
      "category\n",
      "Online Financial Fraud                            1072\n",
      "Crime Against Women & Children                    1072\n",
      "Hacking  Damage to computercomputer system etc    1072\n",
      "Online and Social Media Related Crime             1072\n",
      "Any Other Cyber Crime                             1072\n",
      "Cyber Attack/ Dependent Crimes                    1072\n",
      "Online Cyber Trafficking                           540\n",
      "Cyber Terrorism                                    480\n",
      "Cryptocurrency Crime                               466\n",
      "Ransomware                                         448\n",
      "Online Gambling  Betting                           436\n",
      "Report Unlawful Content                            350\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CybercrimeDataset(Dataset):\n",
    "    def __init__(self, texts, category_labels, subcategory_labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.category_labels = category_labels\n",
    "        self.subcategory_labels = subcategory_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        text = ' '.join(text.split())  # Clean extra spaces\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'category_labels': torch.FloatTensor(self.category_labels[idx]),\n",
    "            'subcategory_labels': torch.FloatTensor(self.subcategory_labels[idx])\n",
    "        }\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def balance_dataset(df):\n",
    "    majority_classes = [\n",
    "        'Online Financial Fraud', 'Any Other Cyber Crime', 'Crime Against Women & Children',\n",
    "        'Cyber Attack/ Dependent Crimes', 'Online and Social Media Related Crime',\n",
    "        'Hacking  Damage to computercomputer system etc', 'Cyber Stalking',\n",
    "        'Cryptocurrency Crime'\n",
    "    ]\n",
    "    \n",
    "    # Define multiplication factors for severely undersampled categories\n",
    "    multiplication_factors = {\n",
    "        'Report Unlawful Content': 350,  # Multiply samples by 100 to get ~300 samples\n",
    "        'Ransomware': 8,                 # Multiply samples by 6 to get ~1000 samples\n",
    "        'Cyber Terrorism': 3,\n",
    "        'Online Cyber Trafficking': 3\n",
    "    }\n",
    "\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    print(\"Available categories:\", df['category'].unique())\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        try:\n",
    "            category_df = df[df['category'] == category]\n",
    "            \n",
    "            if category in multiplication_factors:\n",
    "                # Multiply samples for severely undersampled categories\n",
    "                factor = multiplication_factors[category]\n",
    "                # Add some random noise to avoid exact duplicates\n",
    "                augmented_dfs = []\n",
    "                for _ in range(factor):\n",
    "                    temp_df = category_df.copy()\n",
    "                    # Add slight variations to text to avoid exact duplicates\n",
    "                    temp_df['crimeaditionalinfo'] = temp_df['crimeaditionalinfo'].apply(\n",
    "                        lambda x: x + f\" variation_{_}\")\n",
    "                    augmented_dfs.append(temp_df)\n",
    "                balanced_df = pd.concat(augmented_dfs)\n",
    "                \n",
    "            elif category in majority_classes:\n",
    "                # Reduce majority classes to target size\n",
    "                target_size = 1072  # Keep the current majority size\n",
    "                balanced_df = category_df.sample(n=min(len(category_df), target_size), \n",
    "                                              random_state=42)\n",
    "            else:\n",
    "                # Keep other categories as is\n",
    "                balanced_df = category_df\n",
    "                \n",
    "            balanced_dfs.append(balanced_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Category '{category}' skipped due to: {str(e)}\")\n",
    "            balanced_dfs.append(category_df)\n",
    "    \n",
    "    final_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    \n",
    "    # Print the final distribution\n",
    "    print(\"\\nFinal category distribution:\")\n",
    "    print(final_df['category'].value_counts())\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def create_dataloaders(df, tokenizer, batch_size=16):\n",
    "    # Clean text\n",
    "    df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(lambda x: str(x).lower().strip())\n",
    "    \n",
    "    # Balance dataset\n",
    "    balanced_df = balance_dataset(df)\n",
    "    \n",
    "    # Save balanced dataset to CSV\n",
    "    balanced_df.to_csv('balancedtrain.csv', index=False)\n",
    "    print(f\"Balanced dataset saved to 'balancedtrain.csv' with {len(balanced_df)} samples\")\n",
    "    print(\"Category distribution in balanced dataset:\")\n",
    "    print(balanced_df['category'].value_counts())\n",
    "    \n",
    "    # Prepare labels\n",
    "    mlb_category = MultiLabelBinarizer()\n",
    "    mlb_subcategory = MultiLabelBinarizer()\n",
    "    \n",
    "    # Transform labels\n",
    "    category_encoded = mlb_category.fit_transform(\n",
    "        balanced_df['category'].apply(lambda x: [x])\n",
    "    )\n",
    "    subcategory_encoded = mlb_subcategory.fit_transform(\n",
    "        balanced_df['sub_category'].apply(lambda x: [x])\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = CybercrimeDataset(\n",
    "        balanced_df['crimeaditionalinfo'].values,\n",
    "        category_encoded,\n",
    "        subcategory_encoded,\n",
    "        tokenizer,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Create dataloader with balanced sampling\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader, mlb_category, mlb_subcategory\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_csv('output_no_duplicates.csv')\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader, mlb_category, mlb_subcategory = create_dataloaders(\n",
    "        df,\n",
    "        tokenizer,\n",
    "        batch_size=16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available categories: ['Online Financial Fraud' 'Crime Against Women & Children'\n",
      " 'Hacking  Damage to computercomputer system etc'\n",
      " 'Online and Social Media Related Crime' 'Any Other Cyber Crime'\n",
      " 'Cyber Attack/ Dependent Crimes' 'Cryptocurrency Crime'\n",
      " 'Online Cyber Trafficking' 'Cyber Terrorism' 'Online Gambling  Betting'\n",
      " 'Ransomware' 'Report Unlawful Content']\n",
      "\n",
      "Final category distribution:\n",
      "category\n",
      "Online Financial Fraud                            5000\n",
      "Crime Against Women & Children                    5000\n",
      "Hacking  Damage to computercomputer system etc    5000\n",
      "Online and Social Media Related Crime             5000\n",
      "Any Other Cyber Crime                             5000\n",
      "Cyber Attack/ Dependent Crimes                    5000\n",
      "Cryptocurrency Crime                              5000\n",
      "Online Cyber Trafficking                          5000\n",
      "Cyber Terrorism                                   5000\n",
      "Online Gambling  Betting                          5000\n",
      "Ransomware                                        5000\n",
      "Report Unlawful Content                           5000\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset saved to 'balancedtrain.csv' with 60000 samples\n",
      "Category distribution in balanced dataset:\n",
      "category\n",
      "Online Financial Fraud                            5000\n",
      "Crime Against Women & Children                    5000\n",
      "Hacking  Damage to computercomputer system etc    5000\n",
      "Online and Social Media Related Crime             5000\n",
      "Any Other Cyber Crime                             5000\n",
      "Cyber Attack/ Dependent Crimes                    5000\n",
      "Cryptocurrency Crime                              5000\n",
      "Online Cyber Trafficking                          5000\n",
      "Cyber Terrorism                                   5000\n",
      "Online Gambling  Betting                          5000\n",
      "Ransomware                                        5000\n",
      "Report Unlawful Content                           5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class CybercrimeDataset(Dataset):\n",
    "    def __init__(self, texts, category_labels, subcategory_labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.category_labels = category_labels\n",
    "        self.subcategory_labels = subcategory_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        text = ' '.join(text.split())  # Clean extra spaces\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'category_labels': torch.FloatTensor(self.category_labels[idx]),\n",
    "            'subcategory_labels': torch.FloatTensor(self.subcategory_labels[idx])\n",
    "        }\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def balance_dataset(df):\n",
    "    target_size = 5000  # Target size for all categories\n",
    "    \n",
    "    # Calculate multiplication factors based on current sizes\n",
    "    category_counts = df['category'].value_counts()\n",
    "    multiplication_factors = {}\n",
    "    \n",
    "    for category, count in category_counts.items():\n",
    "        if count < target_size:\n",
    "            # Calculate factor needed to reach close to target_size\n",
    "            factor = int(np.ceil(target_size / count))\n",
    "            multiplication_factors[category] = factor\n",
    "    \n",
    "    balanced_dfs = []\n",
    "    print(\"Available categories:\", df['category'].unique())\n",
    "    \n",
    "    for category in df['category'].unique():\n",
    "        try:\n",
    "            category_df = df[df['category'] == category]\n",
    "            current_count = len(category_df)\n",
    "            \n",
    "            if current_count > target_size:\n",
    "                # Downsample categories that are above target size\n",
    "                balanced_df = category_df.sample(n=target_size, random_state=42)\n",
    "            \n",
    "            elif category in multiplication_factors:\n",
    "                # Multiply samples for undersampled categories\n",
    "                factor = multiplication_factors[category]\n",
    "                augmented_dfs = []\n",
    "                for i in range(factor):\n",
    "                    temp_df = category_df.copy()\n",
    "                    # Add variations to text to avoid exact duplicates\n",
    "                    temp_df['crimeaditionalinfo'] = temp_df['crimeaditionalinfo'].apply(\n",
    "                        lambda x: f\"{x} variation_{i}\")\n",
    "                    augmented_dfs.append(temp_df)\n",
    "                balanced_df = pd.concat(augmented_dfs)\n",
    "                \n",
    "                # If we overshot the target, downsample to target_size\n",
    "                if len(balanced_df) > target_size:\n",
    "                    balanced_df = balanced_df.sample(n=target_size, random_state=42)\n",
    "            \n",
    "            else:\n",
    "                balanced_df = category_df\n",
    "            \n",
    "            balanced_dfs.append(balanced_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Category '{category}' skipped due to: {str(e)}\")\n",
    "            balanced_dfs.append(category_df)\n",
    "    \n",
    "    final_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nFinal category distribution:\")\n",
    "    print(final_df['category'].value_counts())\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def create_dataloaders(df, tokenizer, batch_size=16):\n",
    "    # Clean text\n",
    "    df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(lambda x: str(x).lower().strip())\n",
    "    \n",
    "    # Balance dataset\n",
    "    balanced_df = balance_dataset(df)\n",
    "    \n",
    "    # Save balanced dataset to CSV\n",
    "    balanced_df.to_csv('balancedtrain.csv', index=False)\n",
    "    print(f\"Balanced dataset saved to 'balancedtrain.csv' with {len(balanced_df)} samples\")\n",
    "    print(\"Category distribution in balanced dataset:\")\n",
    "    print(balanced_df['category'].value_counts())\n",
    "    \n",
    "    # Prepare labels\n",
    "    mlb_category = MultiLabelBinarizer()\n",
    "    mlb_subcategory = MultiLabelBinarizer()\n",
    "    \n",
    "    # Transform labels\n",
    "    category_encoded = mlb_category.fit_transform(\n",
    "        balanced_df['category'].apply(lambda x: [x])\n",
    "    )\n",
    "    subcategory_encoded = mlb_subcategory.fit_transform(\n",
    "        balanced_df['sub_category'].apply(lambda x: [x])\n",
    "    )\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = CybercrimeDataset(\n",
    "        balanced_df['crimeaditionalinfo'].values,\n",
    "        category_encoded,\n",
    "        subcategory_encoded,\n",
    "        tokenizer,\n",
    "        max_length=256\n",
    "    )\n",
    "    \n",
    "    # Create dataloader with balanced sampling\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return dataloader, mlb_category, mlb_subcategory\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    df = pd.read_csv('output_no_duplicates.csv')\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader, mlb_category, mlb_subcategory = create_dataloaders(\n",
    "        df,\n",
    "        tokenizer,\n",
    "        batch_size=16\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indiaai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
